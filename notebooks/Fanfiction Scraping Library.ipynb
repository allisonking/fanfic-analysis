{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with an existing scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is intended for playing around with web scraping, particularly for [FanFiction.net](https://www.fanfiction.net).\n",
    "\n",
    "This first section will experiment first with the scraping library found at https://github.com/smilli/fanfiction and to see if it will get what I need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the library, initialize the scraper\n",
    "from fanfiction import Scraper\n",
    "scraper = Scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author_id': 1625333,\n",
       " 'canon': 'Harry Potter',\n",
       " 'canon_type': 'Books',\n",
       " 'genres': ['Romance'],\n",
       " 'id': 7127370,\n",
       " 'lang': 'English',\n",
       " 'num_chapters': 38,\n",
       " 'num_favs': 58,\n",
       " 'num_follows': 87,\n",
       " 'num_reviews': 85,\n",
       " 'num_words': 130649,\n",
       " 'published': 1309299920,\n",
       " 'rated': 'Fiction  T',\n",
       " 'status': 'Complete',\n",
       " 'title': 'Something Great',\n",
       " 'updated': 1446343703}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this may or may not be my fan fiction from years ago\n",
    "story_id = 7127370\n",
    "metadata = scraper.scrape_story_metadata(story_id)\n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yup, that's the fan fiction I was thinking of! Let's see when it was published..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1309299920"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "published_timestamp = metadata['published']\n",
    "published_timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see when it was published in a format I would understand..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2011-06-28 18:25:20'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "datetime.datetime.fromtimestamp(int(published_timestamp)).strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Next step is to figure out how to get a ton of Harry Potter story IDs and parse for the metadata of all of those. While keeping in mind fanfiction.net's terms and services too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![screenshot from fanfiction.net](fanficnet_screenshot.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems like all of that metadata is on the list of stories as well. Perhaps I won't need to use this library, but should adapt the library's code to scrape this listing of stories so I'm not pinging fanfiction.net more than necessary, once to get story ids and once to get all metadata. Let's see if we can do that all in one go.\n",
    "\n",
    "Looking at this screenshot, it seems like there might be a problem where 'Published' is listed as '23m ago' which is not a timestamp. Let's see if that's the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7d754e5de2d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstory_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12582445\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscraper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscrape_story_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstory_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/fanfic/lib/python3.6/site-packages/fanfiction/scraper.py\u001b[0m in \u001b[0;36mscrape_story_metadata\u001b[0;34m(self, story_id)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;34m'title'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;34m'updated'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data-xutime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;34m'published'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data-xutime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;34m'lang'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmetadata_parts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;34m'genres'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgenres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "story_id = 12582445\n",
    "metadata = scraper.scrape_story_metadata(story_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually it seems like the problem isn't the '23m ago', but rather that in this case 'updated' should really be 'published' and that there is no 'updated' time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Experimenting with scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of this will be adapted from the code from the above library. I'm thinking that rather than me scraping for all of the story IDs and then using their library to scrape for all of the metadata, can we do it all in one go? To be kind to the FanFiction.net servers :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# we're only going to look at harry potter fanfics \n",
    "base_url = \"https://www.fanfiction.net/book/Harry-Potter\"\n",
    "# this gets appended in order to \n",
    "page_suffix = \"?&srt=1&r=103&p=\"\n",
    "\n",
    "# 30 seconds seems reasonable for a human to quickly scroll through a page\n",
    "rate_limit = 30\n",
    "\n",
    "# let's start with page 1. this would eventually go into a for loop index, I imagine\n",
    "page=23251"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright- now let's make a request and see what we get in return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = '{0}/{1}{2}'.format(base_url, page_suffix, str(page))\n",
    "raw_result = requests.get(url)\n",
    "html = raw_result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_stories_on_page = soup.find_all('div', class_='z-list zhover zpointer ')\n",
    "len(all_stories_on_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"z-list zhover zpointer \" style=\"min-height:77px;border-bottom:1px #cdcdcd solid;\">\n",
      " <a class=\"stitle\" href=\"/s/285322/1/Facing-Life\">\n",
      "  <img class=\"cimage \" height=\"66\" src=\"/static/images/d_60_90.jpg\" style=\"clear:left;float:left;margin-right:3px;padding:2px;border:1px solid #ccc;-moz-border-radius:2px;-webkit-border-radius:2px;\" width=\"50\"/>\n",
      "  Facing Life\n",
      " </a>\n",
      " by\n",
      " <a href=\"/u/58646/Sellene\">\n",
      "  Sellene\n",
      " </a>\n",
      " <a class=\"reviews\" href=\"/r/285322/\">\n",
      "  reviews\n",
      " </a>\n",
      " <div class=\"z-indent z-padtop\">\n",
      "  Sketchy poem.  Repitivie.  Constructive critism needed!\n",
      "  <div class=\"z-padtop2 xgray\">\n",
      "   Rated: K+ - English - Angst/Poetry - Chapters: 1 - Words: 736 - Reviews: 6 - Published:\n",
      "   <span data-xutime=\"989996400\">\n",
      "    5/16/2001\n",
      "   </span>\n",
      "  </div>\n",
      " </div>\n",
      "</div>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# choosing number two because it has some reviews/follows\n",
    "a_story = all_stories_on_page[1]\n",
    "print(a_story.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whew, we're getting there! Here's the first story on page 1. Let's see if we can get all the metadata the way the fanfction library does. We'll ignore canon and canon_type since this will by default be all Harry Potter books. So we're going to look for author ID, title, updated, published, language, genres, number of reviews, number of favorites, number of follows, number of words, completion, and the rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Facing Life'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's start with the title\n",
    "title = a_story.find(class_='stitle').get_text()\n",
    "title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that was the easy  one. I can do this!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/s/285322/1/Facing-Life'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_url = a_story.find(class_='stitle')['href']\n",
    "story_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I guess you could also get the title from that, though it seems like it'd be more annoying since I would then have to deal with spaces. So let's stick with this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 's', '285322', '1', 'Facing-Life']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_url.split(\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'285322'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_id = story_url.split(\"/\")[2]\n",
    "story_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"stitle\" href=\"/s/285322/1/Facing-Life\"><img class=\"cimage \" height=\"66\" src=\"/static/images/d_60_90.jpg\" style=\"clear:left;float:left;margin-right:3px;padding:2px;border:1px solid #ccc;-moz-border-radius:2px;-webkit-border-radius:2px;\" width=\"50\"/>Facing Life</a>,\n",
       " <a href=\"/u/58646/Sellene\">Sellene</a>,\n",
       " <a class=\"reviews\" href=\"/r/285322/\">reviews</a>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_story.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'58646'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turns out author ID isn't always the third one. for some reason sometimes there isn't a > link\n",
    "# so we'll look for /u/ \n",
    "links = a_story.find_all('a')\n",
    "author_url = [link['href'] for link in links if \"/u/\" in link['href']]\n",
    "author_id = author_url[0].split(\"/\")[2]\n",
    "author_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rated: K+ - English - Angst/Poetry - Chapters: 1 - Words: 736 - Reviews: 6 - Published: 5/16/2001'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_div = a_story.find('div', class_=\"z-indent z-padtop\")\n",
    "start = metadata_div.text.index('Rated')\n",
    "metadata_div.text[start:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span data-xutime=\"989996400\">5/16/2001</span>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times = metadata_div.find_all(attrs={'data-xutime':True})\n",
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "def convertTime(time):\n",
    "    return datetime.datetime.fromtimestamp(int(time)).strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001-05-16 03:00:00\n",
      "2001-05-16 03:00:00\n"
     ]
    }
   ],
   "source": [
    "if len(times) == 2:\n",
    "    updated = times[0]['data-xutime']\n",
    "    published = times[1]['data-xutime'] \n",
    "else:\n",
    "    updated = times[0]['data-xutime']\n",
    "    published = updated\n",
    "\n",
    "print(convertTime(updated))\n",
    "print(convertTime(published))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sketchy poem.  Repitivie.  Constructive critism needed!Rated: K+ - English - Angst/Poetry - Chapters: 1 - Words: 736 - Reviews: 6 - Published: 5/16/2001'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_div.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sketchy poem.  Repitivie.  Constructive critism needed!Rated: K+ ',\n",
       " ' English ',\n",
       " ' Angst/Poetry ',\n",
       " ' Chapters: 1 ',\n",
       " ' Words: 736 ',\n",
       " ' Reviews: 6 ',\n",
       " ' Published: 5/16/2001']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looks like things are separated by -'s\n",
    "metadata_parts = metadata_div.get_text().split('-')\n",
    "metadata_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_genres(genre_text):\n",
    "    if genre_text.startswith('Chapters'):\n",
    "        return []\n",
    "    genres = genre_text.split('/')\n",
    "    # Hurt/Comfort is annoying because of the '/'\n",
    "    corrected_genres = []\n",
    "    for genre in genres:\n",
    "        if genre == 'Hurt':\n",
    "            corrected_genres.append('Hurt/Comfort')\n",
    "        elif genre == 'Comfort':\n",
    "            continue\n",
    "        else:\n",
    "            corrected_genres.append(genre)\n",
    "    return corrected_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Angst', 'Poetry']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we'll use that library's nice get_genres function\n",
    "genres = get_genres(metadata_parts[2].strip())\n",
    "genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'English'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language = metadata_parts[1].strip()\n",
    "language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author_id': '58646',\n",
       " 'genres': ['Angst', 'Poetry'],\n",
       " 'id': '285322',\n",
       " 'language': 'English',\n",
       " 'published': 989996400,\n",
       " 'title': 'Facing Life',\n",
       " 'updated': 989996400}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put together what we have so far\n",
    "metadata = {\n",
    "    'id': story_id,\n",
    "    'author_id': author_id,\n",
    "    'title': title,\n",
    "    'updated': int(updated),\n",
    "    'published': int(published),\n",
    "    'language': language,\n",
    "    'genres': genres\n",
    "}\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author_id': '58646',\n",
       " 'genres': ['Angst', 'Poetry'],\n",
       " 'id': '285322',\n",
       " 'language': 'English',\n",
       " 'num_chapters': 1,\n",
       " 'num_reviews': 6,\n",
       " 'num_words': 736,\n",
       " 'published': 989996400,\n",
       " 'sketchy poem.  repitivie.  constructive critism needed!rated': 'K+',\n",
       " 'title': 'Facing Life',\n",
       " 'updated': 989996400}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# much thanks to the original library for this logic\n",
    "for parts in metadata_parts:\n",
    "    parts = parts.strip()\n",
    "    # already dealt with language and genres- everything else should have name: value\n",
    "    tag_and_val = parts.split(':')\n",
    "    if len(tag_and_val) != 2:\n",
    "        continue\n",
    "    tag, val = tag_and_val\n",
    "    tag = tag.strip().lower()\n",
    "    if tag not in metadata:\n",
    "        val = val.strip()\n",
    "        try:\n",
    "            val = int(val.replace(',', ''))\n",
    "            metadata['num_'+tag] = val\n",
    "        except:\n",
    "            metadata[tag] = val\n",
    "\n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright! We will have to deal with 'status' in a different way than the library cause it doesn't show up on the home page in the same way as it does on any given page. I'd also like to get the character associations which the original library doesn't do. \n",
    "\n",
    "It seems like the last metadata portion is either Published, Complete, or the Character listing. So we'll just have to use if's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Published: 5/16/2001'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_part = metadata_parts[len(metadata_parts)-1]\n",
    "last_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Published: 5/16/2001']\n",
      "['Harry P.', 'Hermione G.', 'Remus L.']\n"
     ]
    }
   ],
   "source": [
    "# seems like sometimes there are brackets and sometimes there aren't...\n",
    "def get_characters(character_text):\n",
    "    stripped = character_text.strip()\n",
    "    bracketless = stripped.replace('[', \"\")\n",
    "    if bracketless.endswith(']'):\n",
    "        characters = bracketless.replace(']', \"\")\n",
    "    else:\n",
    "        characters = bracketless.replace(']', \",\")\n",
    "    return characters.split(', ')\n",
    "    \n",
    "print(get_characters(last_part))\n",
    "print(get_characters(' [Harry P., Hermione G.] Remus L.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Harry P.', 'Hermione G.'], 'James P.', 'Remus L.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = ' [Remus L., Sirius B.] [Lily Evans P., James P.]' # [['Remus L.', 'Sirius B.'], ['Lily Evans P.', 'James P.']]\n",
    "test2 = ' [Harry P., Hermione G.] James P. ' # [['Harry P.', 'Hermione G.'], 'James P.']\n",
    "test3 = ' Lily Evans P., Severus S., Petunia D., OC'\n",
    "test4 = ' [Harry P., Hermione G.] James P., Remus L. '\n",
    "\n",
    "def get_characters_from_string(string):\n",
    "    stripped = string.strip()\n",
    "    if stripped.find('[') == -1:\n",
    "        return stripped.split(', ')\n",
    "    else:\n",
    "        characters = []\n",
    "        num_pairings = stripped.count('[')\n",
    "        for idx in range(0, num_pairings):\n",
    "            open_bracket = stripped.find('[')\n",
    "            close_bracket = stripped.find(']')\n",
    "            characters.append(get_characters_from_string(stripped[open_bracket+1:close_bracket]))\n",
    "            stripped = stripped[close_bracket+1:]\n",
    "        if stripped != '':\n",
    "            singles = get_characters_from_string(stripped)\n",
    "            [characters.append(character) for character in singles]\n",
    "        return characters\n",
    "\n",
    "get_characters_from_string(test4)\n",
    "#any(isinstance(el, list) for el in get_characters_from_string(test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Published: 5/16/2001']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_characters_from_string(last_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author_id': '58646',\n",
       " 'characters': ['Published: 5/16/2001'],\n",
       " 'genres': [],\n",
       " 'id': '285308',\n",
       " 'language': 'English',\n",
       " 'num_chapters': 1,\n",
       " 'num_reviews': 6,\n",
       " 'num_words': 1135,\n",
       " 'published': 989996400,\n",
       " 'status': 'Incomplete',\n",
       " \"three diary entries from back in the mwpp times.  one girl discovers the gift of friendship and its resembolence to a quote about lemonade.  a little silly; the first two entries are..well read it for yourself.  please r/r (don't expect the best; i wroterated\": 'K',\n",
       " 'title': 'Lemonade: The Gift of Friendship',\n",
       " 'updated': 989996400}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if last_part.strip() == 'Complete':\n",
    "    metadata['status'] = 'Complete'\n",
    "    metadata['characters'] = get_characters_from_string(metadata_parts[len(metadata_parts)-2])\n",
    "else:\n",
    "    metadata['status'] = 'Incomplete'\n",
    "    if last_part.startswith('Published'):\n",
    "        metadata['characters'] = []\n",
    "    else:\n",
    "        metadata['characters'] = get_characters_from_string(last_part)\n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think that's everything! Now let's put it into one function and see how it does...\n",
    "\n",
    "## One function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from fanfiction import Scraper\n",
    "\n",
    "def scrape_all_stories_on_page(url):\n",
    "    # names of the classes on fanfiction.net\n",
    "    story_root_class = 'z-list zhover zpointer '\n",
    "    \n",
    "    html = requests.get(url).content\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "    # get all the stories on the page\n",
    "    all_stories_on_page = soup.find_all('div', class_=story_root_class)\n",
    "    metadata_list = {}\n",
    "    for story in all_stories_on_page:\n",
    "        id, metadata = scrape_story_blurb(story)\n",
    "        metadata_list[id] = metadata\n",
    "    return metadata_list\n",
    "        \n",
    "def scrape_story_blurb(story):\n",
    "    # names of the classes on fanfiction.net\n",
    "    title_class = 'stitle'\n",
    "    metadata_div_class = 'z-padtop2 xgray'\n",
    "    \n",
    "    title = story.find(class_=title_class).get_text()\n",
    "    story_id = story.find(class_=title_class)['href'].split(\"/\")[2]\n",
    "    \n",
    "    # some steps to get to the author id\n",
    "    links = story.find_all('a')\n",
    "    author_url = [link['href'] for link in links if \"/u/\" in link['href']]\n",
    "    author_id = author_url[0].split(\"/\")[2]\n",
    "    \n",
    "    metadata_div = story.find('div', class_=metadata_div_class)\n",
    "    \n",
    "    times = metadata_div.find_all(attrs={'data-xutime':True})\n",
    "    if len(times) == 2:\n",
    "        updated = times[0]['data-xutime']\n",
    "        published = times[1]['data-xutime']\n",
    "    else:\n",
    "        updated = times[0]['data-xutime']\n",
    "        published = updated\n",
    "    \n",
    "    metadata_parts = metadata_div.get_text().split('-')\n",
    "    scraper = Scraper()\n",
    "    genres = scraper.get_genres(metadata_parts[2].strip())\n",
    "    \n",
    "    language = metadata_parts[1].strip()\n",
    "    \n",
    "    metadata = {\n",
    "        'author_id': author_id,\n",
    "        'title': title,\n",
    "        'updated': int(updated),\n",
    "        'published': int(published),\n",
    "        'language': language,\n",
    "        'genres': genres\n",
    "    }\n",
    "    \n",
    "    for parts in metadata_parts:\n",
    "        parts = parts.strip()\n",
    "        # already dealt with language and genres- everything else should have name: value\n",
    "        tag_and_val = parts.split(':')\n",
    "        if len(tag_and_val) != 2:\n",
    "            continue\n",
    "        tag, val = tag_and_val\n",
    "        tag = tag.strip().lower()\n",
    "        if tag not in metadata:\n",
    "            val = val.strip()\n",
    "            try:\n",
    "                val = int(val.replace(',', ''))\n",
    "                metadata['num_'+tag] = val\n",
    "            except:\n",
    "                metadata[tag] = val\n",
    "    \n",
    "    # see if we have characters and/or completion\n",
    "    last_part = metadata_parts[len(metadata_parts)-1]\n",
    "    if last_part == 'Complete':\n",
    "        metadata['status'] = 'Complete'\n",
    "        # have to get the second to last now\n",
    "        metadata['characters'] = get_characters(metadata_parts[len(metadata_parts)-2])\n",
    "    else:\n",
    "        metadata['status'] = 'Incomplete'\n",
    "        metadata['characters'] = get_characters(last_part)\n",
    "        \n",
    "    return story_id, metadata    \n",
    "\n",
    "def get_characters(character_text):\n",
    "    altered = character_text.strip().replace('[', \"\")\n",
    "    if altered.startswith('Published'):\n",
    "        return []\n",
    "    else:\n",
    "        if altered.endswith(']'):\n",
    "            characters = altered.replace(']', \"\")\n",
    "        else:\n",
    "            characters = altered.replace(']', \",\")\n",
    "        return characters.split(', ')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raven and the Philosopher Stone\n",
      "[]\n",
      "['Adventure']\n"
     ]
    }
   ],
   "source": [
    "scraped_data = scrape_all_stories_on_page(url)\n",
    "example_key = list(scraped_data.keys())[0]\n",
    "print(scraped_data[example_key]['title'])\n",
    "print(scraped_data[example_key]['characters'])\n",
    "print(scraped_data[example_key]['genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "filename = '20170723_page1.json'\n",
    "with open(filename, 'w') as outfile:\n",
    "    json.dump(scraped_data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raven and the Philosopher Stone\n",
      "[]\n",
      "['Adventure']\n"
     ]
    }
   ],
   "source": [
    "# make sure we can open it and that it is the same\n",
    "json_data = open(filename).read()\n",
    "data = json.loads(json_data)\n",
    "print(data[example_key]['title'])\n",
    "print(data[example_key]['characters'])\n",
    "print(data[example_key]['genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"/book/Harry-Potter/?&amp;srt=1&amp;r=103&amp;p=23517\">Â« Prev</a>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "pattern = re.compile(r'Last')\n",
    "soup.find('center').find('a')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author_id': '1068464',\n",
       " 'characters': [['Hermione G.', 'Severus S.'], 'Harry P.'],\n",
       " 'genres': ['Romance', 'Humor'],\n",
       " 'language': 'English',\n",
       " 'num_chapters': 1,\n",
       " 'num_favs': 1,\n",
       " 'num_follows': 1,\n",
       " 'num_reviews': 1,\n",
       " 'num_words': 1114,\n",
       " 'published': 1501191659,\n",
       " 'rated': 'T',\n",
       " 'status': 'Complete',\n",
       " 'title': 'The Termination',\n",
       " 'updated': 1501191659}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity checking from the .py\n",
    "import json\n",
    "\n",
    "json_data = open('../src/fanfic/scrape/data.json')\n",
    "data = json.load(json_data)\n",
    "example_key = list(data.keys())[72]\n",
    "#[data[key]['title'] for key in data.keys()]\n",
    "data[example_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
