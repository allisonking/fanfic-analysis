{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with an existing scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is intended for playing around with web scraping, particularly for [FanFiction.net](https://www.fanfiction.net).\n",
    "\n",
    "This first section will experiment first with the scraping library found at https://github.com/smilli/fanfiction and to see if it will get what I need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the library, initialize the scraper\n",
    "from fanfiction import Scraper\n",
    "scraper = Scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author_id': 1625333,\n",
       " 'canon': 'Harry Potter',\n",
       " 'canon_type': 'Books',\n",
       " 'genres': ['Romance'],\n",
       " 'id': 7127370,\n",
       " 'lang': 'English',\n",
       " 'num_chapters': 38,\n",
       " 'num_favs': 58,\n",
       " 'num_follows': 87,\n",
       " 'num_reviews': 85,\n",
       " 'num_words': 130649,\n",
       " 'published': 1309299920,\n",
       " 'rated': 'Fiction  T',\n",
       " 'status': 'Complete',\n",
       " 'title': 'Something Great',\n",
       " 'updated': 1446343703}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this may or may not be my fan fiction from years ago\n",
    "story_id = 7127370\n",
    "metadata = scraper.scrape_story_metadata(story_id)\n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yup, that's the fan fiction I was thinking of! Let's see when it was published..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1309299920"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "published_timestamp = metadata['published']\n",
    "published_timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see when it was published in a format I would understand..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2011-06-28 18:25:20'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "datetime.datetime.fromtimestamp(int(published_timestamp)).strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Next step is to figure out how to get a ton of Harry Potter story IDs and parse for the metadata of all of those. While keeping in mind fanfiction.net's terms and services too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![screenshot from fanfiction.net](fanficnet_screenshot.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems like all of that metadata is on the list of stories as well. Perhaps I won't need to use this library, but should adapt the library's code to scrape this listing of stories so I'm not pinging fanfiction.net more than necessary, once to get story ids and once to get all metadata. Let's see if we can do that all in one go.\n",
    "\n",
    "Looking at this screenshot, it seems like there might be a problem where 'Published' is listed as '23m ago' which is not a timestamp. Let's see if that's the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7d754e5de2d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstory_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12582445\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscraper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscrape_story_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstory_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/fanfic/lib/python3.6/site-packages/fanfiction/scraper.py\u001b[0m in \u001b[0;36mscrape_story_metadata\u001b[0;34m(self, story_id)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;34m'title'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;34m'updated'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data-xutime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;34m'published'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data-xutime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;34m'lang'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmetadata_parts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;34m'genres'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgenres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "story_id = 12582445\n",
    "metadata = scraper.scrape_story_metadata(story_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yup, seems like it. Either I can write code to handle that, or we can just ignore all fan fiction published today, which wouldn't affect the overall goal of this project. I'm guessing this will also affect 'updated' which isn't relevant either. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Experimenting with scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of this will be adapted from the code from the above library. I'm thinking that rather than me scraping for all of the story IDs and then using their library to scrape for all of the metadata, can we do it all in one go? To be kind to the FanFiction.net servers :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# we're only going to look at harry potter fanfics \n",
    "base_url = \"https://www.fanfiction.net/book/Harry-Potter\"\n",
    "# this gets appended in order to \n",
    "page_suffix = \"?&srt=1&r=103&p=\"\n",
    "\n",
    "# 30 seconds seems reasonable for a human to quickly scroll through a page\n",
    "rate_limit = 30\n",
    "\n",
    "# let's start with page 1. this would eventually go into a for loop index, I imagine\n",
    "page=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright- now let's make a request and see what we get in return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = '{0}/{1}{2}'.format(base_url, page_suffix, str(page))\n",
    "raw_result = requests.get(url)\n",
    "html = raw_result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_stories_on_page = soup.find_all('div', class_='z-list zhover zpointer ')\n",
    "len(all_stories_on_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"z-list zhover zpointer \" style=\"min-height:77px;border-bottom:1px #cdcdcd solid;\">\n",
      " <a class=\"stitle\" href=\"/s/12565468/1/Reasons\">\n",
      "  <img class=\"lazy cimage \" data-original=\"//ffcdn2012t-fictionpressllc.netdna-ssl.com/image/4778442/75/\" height=\"66\" src=\"/static/images/d_60_90.jpg\" style=\"clear:left;float:left;margin-right:3px;padding:2px;border:1px solid #ccc;-moz-border-radius:2px;-webkit-border-radius:2px;\" width=\"50\"/>\n",
      "  Reasons\n",
      " </a>\n",
      " <a href=\"/s/12565468/4/Reasons\">\n",
      "  <span class=\"icon-chevron-right xicon-section-arrow\">\n",
      "  </span>\n",
      " </a>\n",
      " by\n",
      " <a href=\"/u/6457851/ILoveHarmony\">\n",
      "  ILoveHarmony\n",
      " </a>\n",
      " <a class=\"reviews\" href=\"/r/12565468/\">\n",
      "  reviews\n",
      " </a>\n",
      " <div class=\"z-indent z-padtop\">\n",
      "  Reasons to love Hermione Jean Granger -by Harry James Potter\n",
      "  <div class=\"z-padtop2 xgray\">\n",
      "   Rated: T - English - Romance/Humor - Chapters: 4 - Words: 3,983 - Reviews: 7 - Favs: 17 - Follows: 18 - Updated:\n",
      "   <span data-xutime=\"1500814509\">\n",
      "    40m\n",
      "   </span>\n",
      "   - Published:\n",
      "   <span data-xutime=\"1499632097\">\n",
      "    7/9\n",
      "   </span>\n",
      "   - [Harry P., Hermione G.]\n",
      "  </div>\n",
      " </div>\n",
      "</div>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# choosing number two because it has some reviews/follows\n",
    "a_story = all_stories_on_page[2]\n",
    "print(a_story.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whew, we're getting there! Here's the first story on page 1. Let's see if we can get all the metadata the way the fanfction library does. We'll ignore canon and canon_type since this will by default be all Harry Potter books. So we're going to look for author ID, title, updated, published, language, genres, number of reviews, number of favorites, number of follows, number of words, completion, and the rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reasons'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's start with the title\n",
    "title = a_story.find(class_='stitle').getText()\n",
    "title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that was the easy  one. I can do this!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/s/12565468/1/Reasons'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_url = a_story.find(class_='stitle')['href']\n",
    "story_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I guess you could also get the title from that, though it seems like it'd be more annoying since I would then have to deal with spaces. So let's stick with this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 's', '12565468', '1', 'Reasons']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_url.split(\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12565468'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "story_id = story_url.split(\"/\")[2]\n",
    "story_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"stitle\" href=\"/s/12565468/1/Reasons\"><img class=\"lazy cimage \" data-original=\"//ffcdn2012t-fictionpressllc.netdna-ssl.com/image/4778442/75/\" height=\"66\" src=\"/static/images/d_60_90.jpg\" style=\"clear:left;float:left;margin-right:3px;padding:2px;border:1px solid #ccc;-moz-border-radius:2px;-webkit-border-radius:2px;\" width=\"50\"/>Reasons</a>,\n",
       " <a href=\"/s/12565468/4/Reasons\"><span class=\"icon-chevron-right xicon-section-arrow\"></span></a>,\n",
       " <a href=\"/u/6457851/ILoveHarmony\">ILoveHarmony</a>,\n",
       " <a class=\"reviews\" href=\"/r/12565468/\">reviews</a>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_story.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"/u/6457851/ILoveHarmony\">ILoveHarmony</a>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looks like the <a> for author id isn't an ID. hopefully it's always the third one\n",
    "a_story.find_all('a')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6457851'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_url = a_story.find_all('a')[2]['href']\n",
    "author_id = author_url.split(\"/\")[2]\n",
    "author_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
